\label{sec:Conclusioni}
Il modello di programmazione CUDA ha uno stile progettuale intrinseco che complica l'implementazione di \textit{round}. È impossibile sincronizzare l'esecuzione e le transazioni della memoria globale dei thread nei diversi blocchi all'interno di un kernel in esecuzione. Questo significa che alla fine di un set, quando il blocco $b_1$ scrive le colonne ortogonalizzate nella global memory, non c'è modo per garantire che il blocco $b_2$ vedrà e leggerà le colonne aggiornate all'inizio del set successivo.

L'unico modo per i thread contenuti in diversi blocchi di sincronizzare e condividere i dati è di richiamare il kernel dopo che ogni blocco ha scritto i suoi risultati nella memoria globale. Ciò limita lo scopo di \textit{round} e forza l'host a richiamare il kernel una volta per set. Questo comporta le seguenti conseguenze indesiderabili:
\begin{itemize}
	\item Per ogni esecuzione di \textit{round}, ogni blocco di thread deve leggere le colonne della matrice dalla memoria globale nella shared memory o solo dalla memoria globale in base all'algoritmo implementato.
	
	
	Al contrario, se fosse possibile la sincronizzazione tra blocchi di thread, sarebbe possibile elaborare uno schema di partizionamento di coppie di colonne più efficiente. Un tale schema minimizzerebbe il numero di letture di memoria globale richieste da un blocco all'inizio di un nuovo set.
	
	\item Il test di convergenza deve essere eseguito sull'host. Occorre quindi copiare il valore \textit{exit\_flag} dal device all'host tramite \text{cudaMemcpy} alla fine di ogni set per determinare se è necessario continuare a chiamare il kernel \textit{round}. 
	
	Poiché l'host deve leggere la memoria del device dopo ogni set, ciò ha l'effetto di sincronizzare implicitamente l'host con il device dopo ogni chiamata di \textit{round}. Ciò riduce di molto le possibilità di esecuzione simultanea del kernel, che a sua volta limita il throughput totale.
\end{itemize}
In linea di principio, una SVD basata sul metodo One-Sided Jacobi può essere adattata per sfruttare dispositivi con elevate capacità di parallelismo. Tuttavia, le caratteristiche fondamentali del modello di programmazione e dell'architettura hardware delle GPU NVIDIA rendono in pratica l'approccio di cui sopra difficile da applicare. In particolare, la mancanza di sincronizzazione sia tra i thread sia tra l'host e il device dopo ogni set comportano un sovraccarico aggiuntivo che alla fine limita la potenzialità di sfruttare appieno le capacità di calcolo della GPU.\cite{Romer:SVD}

Un altro approccio per la SVD è presentato in~\cite{Boukaram:SVD}. È molto importante quando non possiamo più memorizzare l'intera matrice nella memoria shared a causa della dimensione elevata della matrice, dobbiamo quindi operare con la memoria globale che è più lenta. Invece di leggere e aggiornare ripetutamente le colonne una alla volta, gli algoritmi a blocchi possono operare con blocchi di colonne.

Sono illustrati due algoritmi per implementare l'algoritmo One-Sided Jacobi sulla memoria globale che differiscono solo nel modo in cui le colonne dei blocchi vengono ortogonalizzate. In queste implementazioni vengono utilizzate le routine della libreria cuSOLVER 8. La nostra GPU Jetson non può usare questa libreria perché lavora con la versione 6.5 di CUDA e ha una capacità di calcolo pari 3.2.

Le prestazioni mostrate nel capitolo~\ref{sec:Performance} per l'implementazione dell'approccio sopra indicato sono state eseguite su un pc con CPU Intel i7-3630 QM @2.40 GHz, 8GB of RAM e una GPU NVIDIA Geforce GTX 610M. Per ulteriori lavori, in futuro, si consiglia di eseguire gli algoritmi descritti con una GPU ad alte prestazioni che può utilizzare le librerie cuSOLVER e con una compute capability $\geq 3.5$: ciò consente al programmatore di aumentare il parallelismo usando kernel che hanno la possibilità di invocare altri kernel e di sfruttare librerie altamente ottimizzate per il calcolo parallelo.