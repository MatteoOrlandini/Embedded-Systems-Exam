The CUDA programming model has an inherent design trait that complicates the implementation of \textit{round}. In short, it is impossible to synchronize the execution and global memory transactions of threads in different thread blocks within a running kernel. Without loss of generality, for \textit{round} this means that at the end of a set when thread block b1 writes its orthogonalized columns back to global memory, there is no way to guarantee that thread block b2 will see and read in either of the updated columns at the start of the next set.

In practice, the only way for threads in different thread blocks to synchronize and share data is to relaunch the kernel after each thread block has written its initial results to global memory. This restricts the scope of \textit{round} and forces the host to launch the kernel once per set. This results in the following undesirable consequences:
\begin{itemize}
	\item For every run of \textit{round}, each thread block must read the matrix columns from global	memory into shared memory or only from global memory in base of the implemented algorithm. Since the contents of shared memory are transient, this guarantees that each thread block on every set pays the penalty for reading four column vectors from global memory.
	
	In contrast, if synchronization across thread blocks were possible, it is possible a more intelligent column pair partitioning scheme could be devised. Ideally, such a scheme would minimize the number of global	memory reads a thread block requires at the start of a new set.
	\item Convergence testing must be done on the host. This requires a counter to be stored in global memory that is incremented for each thread block whose column pair is already sufficiently orthogonal. The host then needs to read this value at the end of each set to determine if it needs to continue calling \textit{round}. 
	
	Since the host must read memory from the device after every set, this has the effect of implicitly synchronizing the host with the device after every invocation of \textit{round}. This effectively reduces, if not eliminates,	possibilities for concurrent kernel execution, which in turn limits total throughput.
\end{itemize}

The runtime performance shown in~\ref{sec:Performace} for the implementation of the approach given above was measured on a laptop equipped with an Intel i7-3630 QM 2.40 GHz CPU, 8GB of RAM, and the aforementioned Geforce GTX 610M.

In principle, an SVD based on the one-sided Jacobi method can be adapted to exploit readily available devices with massively parallel capabilities. With it, it is possible to achieve a high degree of thread-level parallelism that is on the order of the number of elements in the matrix.

However, core characteristics of both the programming model and hardware architecture of NVIDIA GPUs make the above approach a bit of a mismatch for them in practice. Most notably a lack of grid-level thread synchronization forces the orthogonalization process to be spread out over multiple kernel invocations. Consequently, the host is forced to synchronize with the device after each set, and the device is unable reduce global memory transactions between sets through caching of data in shared memory. Both of these result in additional overhead that ultimately limits the ability to fully exploit the compute capabilities of the GPU.

Another approach for the SVD is presented in~\cite{Boukaram:SVD}. It's very important when we can no longer store the entire matrix in shared memory, we have to operate on the
matrix in the slower global memory. Instead of repeatedly reading and updating the columns one at a time, block algorithms can operate with blocks of columns.

There are two global memory block Jacobi algorithms that differ only in the way block columns are orthogonalized and there is a comparison of their performance with parallel streamed calls to the cuSOLVER 8 library routines. Our Jetson GPU cannot use this library because we are using CUDA 6.5 and it has a 3.2 compute capability. 

For further work it's recommended to perform the algorithms described with a high-performance GPU that can use cuSOLVER libraries and with a $\geq 3.5$ compute capability: this allows the programmer to increase the parallelism using kernels that are invoking other kernels.