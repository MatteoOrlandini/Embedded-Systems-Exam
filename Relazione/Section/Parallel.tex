%Descrizione algoritmo parallel
%Dal capitolo PARALLELIZING THE ONE-SIDED JACOBI nell'articolo Romer
Parallelizzare la One-Sided Jacobi implica il partizionamento di $n(n-1)/2$ coppie di colonne che devono essere ortogonali a ciascuna scansione (sweep) in gruppi di coppie di colonne indipendenti. Ogni sweep viene quindi elaborato un set alla volta, ortogonalizzando in parallelo le coppie di colonne all'interno del set corrente.

Le coppie di colonne per ciascun set vengono generate utilizzando un algoritmo di pianificazione round-robin. Concettualmente, ogni round rappresenta un set e gli abbinamenti all'interno di un round corrispondono agli abbinamenti di colonne all'interno di quel set. Ad esempio, di seguito sono riportati tutti i possibili set contenenti le rispettive coppie di colonne per $n = 6$:
\begin{center}
	Set 1 = $\{(1,2),(3,4),(5,6)\}$\\
	Set 2 = $\{(1,4),(2,6),(3,5)\}$\\
	Set 3 = $\{(1,6),(2,3),(4,5)\}$\\
	Set 4 = $\{(1,5),(2,4),(3,6)\}$\\
	Set 5 = $\{(1,3),(2,5),(4,6)\}$\\
\end{center}
In generale, ogni set contiene $\hat{n}/2$ coppie di colonne ortogonalizzate in parallelo, dove $\hat{n}$ è il prossimo numero intero pari maggiore o uguale a $n$. Se $n$ è dispari, quindi ogni set avrà una colonna accoppiata con una colonna "fantasma"; le coppie che contengono la colonna fantasma non sono ortogonali. In base a questo schema, sono necessari $\hat{n}/2 - 1$ set per completare una sweep completa.

La coppia di colonne $(p', q')$ ortogonalizzata dalla $i-$esima rotazione in un set viene calcolata direttamente dalla coppia di colonne $(p, q)$ corrispondente ortogonalizzata dalla $i-$esima rotazione nel set precedente. In pratica, questo schema è più adatto per l'esecuzione su una GPU in cui la larghezza di banda di calcolo supera notevolmente la larghezza di banda di memoria. \cite{Romer:SVD}

%Dal capitolo Parallel-Order Jacobi algorithm nell'articolo Acosta
Nelle tradizionali implementazioni sequenziali dell'algoritmo Jacobi, il parallelismo non viene sfruttato, principalmente a causa della dipendenza dei dati di una rotazione con la sua precedente. L'algoritmo Jacobi parallelo sfrutta il massimo parallelismo per la decomposizione di una matrice simmetrica. Questo algoritmo richiede un numero di step pari a $n - 1$, in cui in ogni step si compiono $n/2$ rotazioni. Tutte le rotazioni all'interno di uno step possono essere eseguite in parallelo. \cite{Acosta:SVD}

%Dal capitolo IMPLEMENTING THE SVD USING CUDA nell'articolo Romer
Si è usato CUDA per implementare una SVD parallela basata sul metodo One-Sided Jacobi descritto in~\ref{sec:OneSidedJacobi}. La matrice di input $A \quad (m \times n)$ è una matrice reale in cui $m \geq n$. Se $m < n$, la SVD di A può essere calcolata dalla SVD di $A^T = V \Sigma U^T$. Le matrici di input sono salvate in column-major order e single-precision floating point. \cite{Romer:SVD}

Viene ora mostrata l'implementazione in CUDA dell'algoritmo parallel. Il codice che richiama il kernel che esegue l'algoritmo One-Sided Jacobi parallel è il seguente.
\begin{lstlisting}[caption=Loop algoritmo parallelo,label=code:parallel_loop]
while(!host_exit_flag) {
	++iter;
	host_exit_flag = true; 
	cudaMemcpy(dev_exit_flag, &host_exit_flag, sizeof(bool), cudaMemcpyHostToDevice);
	for(int set = 0; set < cols; set++) {
		scheduling<<<1, 1>>> (dev_v1, dev_v2, cols);
		round <<<cols/2, rows>>> (dev_B, dev_v1, dev_v2, cols, rows, dev_exit_flag);		
	}
	cudaMemcpy( &host_exit_flag, dev_exit_flag, sizeof(bool), cudaMemcpyDeviceToHost);
}
\end{lstlisting}
Le variabili \textit{host\_exit\_flag}, \textit{iter} e \textit{B} svolgono le stesse funzioni descritte nel codice~\ref{code:parallel_loop}.

La variabile \textit{set} rappresenta il round attuale dello scheduling round robin. Come spiegato in precedenza, il numero di set necessari per formare tutte le possibili combinazioni sono $n-1$, dove $n$ è il numero di colonne della matrice originale.

I vettori \textit{v1} e  \textit{v2} servono a rappresentare le coppie di colonne. Per ogni set gli elementi dei vettori con lo stesso indice rappresentano una coppia di colonne da ortogonalizzare mutualmente. L'aggiornamento di questi vettori viene effettuato dal kernel \textit{scheduling}.

Il kernel \textit{scheduling} ha lo scopo di ruotare i vettori \textit{v1} e  \textit{v2} ad ogni iterazione del ciclo in cui viene incrementato il valore di \textit{set}. Infatti, per effettuare l'algoritmo di round robin è sufficiente tenere fisso il primo elemento del primo vettore e routare gli altri come se fossero un unico vettore. Quindi, l'elemento 0 che rappresenta la prima colonna sarà sempre alla prima posizione del primo vettore. Gli altri elementi dello stesso vettore scorreranno verso destra, mentre il secondo vettore esegue uno shift verso sinistra. L'elemento uscente dal secondo vettore viene spostato nel posto vacante lasciato dall'elemento 1 di \textit{v1} mentre l'ultimo elemento del primo vettore diventa l'ultimo del secondo.
Ogni iterazione di questo algoritmo viene effettuata sul device. In questo modo, non ci sarà la necessita di copiare i vettori da host a device e viceversa. Il costo computazionale per lanciare un kernel compensa di gran lunga quello che sarebbe stato necessario per le \textit{cudaMemcpy}.
\begin{lstlisting}
__global__ void scheduling (int *v1, int *v2, int cols){
	int tmp = v2[0];
	for (int i = 0; i < (cols/2) - 1; i++)
	v2[i] = v2[i+1];	
	v2[cols/2 - 1] = v1[cols/2 - 1];
	for (int i = (cols/2) -1; i > 1; i--)
	v1[i] = v1[i-1];	
	v1[1] = tmp;
}
\end{lstlisting}

Il kernel \textit{round} chiama un numero di blocchi pari alla metà del numero delle colonne della matrice e un numero di thread pari alle righe della matrice perché ad ogni blocco sarà assegnata una coppia di colonne, mentre i kernel rappresentano gli elementi delle colonne per ogni blocco.

Una volta ricavati i valori identificativi del blocco e del thread attuale, viene estratta da \textit{v1} e  \textit{v2} la coppia corrispondente. Dato ogni blocco ha assegnata una coppia, gli elementi dei vettori con indici corrispondenti al blocco saranno gli indici delle coppie di colonne utilizzati per ogni thread.

I puntatori \textit{pi} e \textit{pj} punteranno agli elementi su cui ogni thread deve lavorare. Perciò, i e j rappresentano le colonne ottenute da \textit{v1} e  \textit{v2}, mentre l'Id del thread indica la riga su cui lavorare (ovvero l'elemento della colonna corrispondente). Tenendo conto del fatto che la matrice B è in memoria in column order, è possibile accedere agli elementi specifici usando i parametri appena descritti.

Le variabili \textit{alpha}, \textit{beta} e \textit{gamm} rappresentano le omonime descritte nella teoria dell'algoritmo di Jacobi. Queste variabile sono salvate nella memoria shared; in questo modo il loro valore è condiviso tra i thread dello stesso blocco. La funzione "atomicAdd" permette ad ogni thread di incrementare il valore delle variabili in maniera sequenziale, evitando collisioni dovute all'accesso in parallelo.
Ogni thread calcola quindi il proprio valore di \textit{alpha}, \textit{beta} e \textit{gamm} per la riga che rappresentano e la aggiungono al valore complessivo che tiene conto della singola coppia su cui il blocco sta lavorando.

Viene calcolato il valore limit con lo scopo di essere confrontato con il valore ammissibile che soddisfa la convergenza. Quando la soglia viene superata, viene modificata la variabile \textit{exit\_flag}, che permette di uscire dalle iterazioni una volta ritornata all'host.

Seguendo le istruzioni spiegate in precedenza, si ricavano i valori delle variabili s e c, che rappresentano seno e coseno della matrice di rotazione. Queste variabili dipendono da \textit{alpha}, \textit{beta} e \textit{gamm}. Sono quindi comuni per ogni coppia di colonne.

Infine, la matrice di rotazione viene applicata ruotando le colonne con i valori adeguati di c e s.

Nei capitoli~\ref{sec:Global},~\ref{sec:Semi_Shared} e~\ref{sec:Shared} sono presentate tre varianti del kernel \textit{round} a seconda della memoria in cui viene immagazzinata la matrice \textit{B}.

Il calcolo dei valori singolari è eseguito dal kernel~\textit{computeSingVals}, codice~\ref{code:computeSingVals}, precedentemente descritto.